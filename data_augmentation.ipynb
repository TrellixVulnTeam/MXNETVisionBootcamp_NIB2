{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods of applying data augmentation (Gluon API)\n",
    "\n",
    "Data Augmentation is a regularization technique that's used to avoid overfitting when training Machine Learning models. Although the technique can be applied in a variety of domains, it's very common in Computer Vision. Adjustments are made to the original images in the training dataset before being used in training. Some example adjustments include translating, cropping, scaling, rotating, changing brightness and contrast. We do this to reduce the dependence of the model on spurious characteristics; e.g. training data may only contain faces that fill 1/4 of the image, so the model trained without data augmentation might unhelpfully learn that faces can only be of this size.\n",
    "\n",
    "In this tutorial we demonstrate a method of applying data augmentation with Gluon using the [`mxnet.gluon.data.vision.datasets.ImageFolderDataset`](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.datasets.ImageFolderDataset) and the [`mxnet.gluon.data.vision.transforms.Compose`](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.transforms.Compose) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx # used version '1.0.0' at time of writing\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "mx.random.seed(42) # set seed for repeatability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a utility function below, that will be used for visualising the augmentations in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mx_array(array):\n",
    "    \"\"\"\n",
    "    Array expected to be height x width x 3 (channels), and values are floats between 0 and 255.\n",
    "    \"\"\"\n",
    "    assert array.shape[2] == 3, \"RGB Channel should be last\"\n",
    "    imshow((array.clip(0, 255)/255).asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = os.path.join('data','images')\n",
    "mx.test_utils.download('https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/data_aug/inputs/0.jpg', dirname=image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = mx.image.imread(os.path.join(image_folder, \"0.jpg\")).astype(\"float32\")\n",
    "plot_mx_array(example_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick start with [`ImageFolderDataset`](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.datasets.ImageFolderDataset)\n",
    "\n",
    "Using Gluon, it's simple to add data augmentation to your training pipeline. When creating either [`ImageFolderDataset`](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.datasets.ImageFolderDataset) or [`ImageRecordDataset`](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.datasets.ImageRecordDataset), you can pass a `transform` function that will be applied to each image in the dataset, every time it's loaded from disk. Augmentations are intended to be random, so you'll pass a slightly different version of the image to the network on each epoch.\n",
    "\n",
    "We define `aug_transform` below to perform a selection of augmentation steps and pass it to our dataset. It's worth noting that augmentations should only be applied to the training data (and not the test data), so you don't want to pass this augmentation transform function to the testing dataset.\n",
    "\n",
    "[`mxnet.image.CreateAugmenter`](https://mxnet.incubator.apache.org/api/python/image/image.html?highlight=createaugmenter#mxnet.image.CreateAugmenter) is a useful function for creating a diverse set of augmentations at once. Despite the singular `CreateAugmenter`, this function actually returns a list of Augmenters. We can then loop through this list and apply each type of augmentation one after another. Although the parameters of `CreateAugmenter` are fixed, the random augmentations (such as `rand_mirror` and `brightness`) will be different each time `aug_transform` is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_transform(data, label):\n",
    "    data = data.astype('float32')/255\n",
    "    augs = mx.image.CreateAugmenter(data_shape=(3, 300, 300),\n",
    "                                    rand_crop=0.5, rand_mirror=True, inter_method=10,\n",
    "                                    brightness=0.125, contrast=0.125, saturation=0.125,\n",
    "                                    pca_noise=0.02)\n",
    "    for aug in augs:\n",
    "        data = aug(data)\n",
    "    return data, label\n",
    "\n",
    "\n",
    "training_dataset = mx.gluon.data.vision.ImageFolderDataset('data', transform=aug_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly inspect the augmentations by indexing the dataset (which calls the `__getitem__` method of the dataset). When this method is called (with an index) the correct image is read from disk, and the `transform` is applied. We can see the result of the augmentations when comparing the image below with the original image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = training_dataset[0]\n",
    "sample_data = sample[0]\n",
    "plot_mx_array(sample_data*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice you should load images from a dataset with a [`mxnet.gluon.data.DataLoader`](https://mxnet.incubator.apache.org/api/python/gluon/data.html?highlight=dataloader#mxnet.gluon.data.DataLoader) to take advantage of automatic batching and shuffling. Under the hood the `DataLoader` calls `__getitem__`, but you shouldn't need to call directly for anything other than debugging. Some practitioners pre-augment their datasets by applying a fixed number of augmentations to each image and saving the outputs to disk with the aim of increased throughput. With the `num_workers` parameter of `DataLoader` you can use all CPU cores to apply the augmentations, which often mitigates the need to perform pre-augmentation; reducing complexity and saving disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "training_data_loader = mx.gluon.data.DataLoader(training_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for data_batch, label_batch in training_data_loader:\n",
    "    plot_mx_array(data_batch[0]*255)\n",
    "    assert data_batch.shape == (1, 300, 300, 3)\n",
    "    assert label_batch.shape == (1,)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transforms with [`Compose`](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.vision.transforms)\n",
    "Transforms can also be used to augment input data during training. You can compose multiple transforms sequentially (taking note of which functions should be applied before and after ToTensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision import MNIST, transforms\n",
    "from mxnet import gluon\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(300),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomBrightness(0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0, 1)])\n",
    "data = MNIST(train=True).transform_first(transform)\n",
    "data_loader = gluon.data.DataLoader(data, batch_size=32, num_workers=1)\n",
    "for data, label in data_loader:\n",
    "    # do something with data and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<!-- INSERT SOURCE DOWNLOAD BUTTONS -->\n"
   ]
  }
 ],
 "metadata": {
  "display_name": "",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
